{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "\n",
    "# Load the JSON data from a file with multiple JSON objects\n",
    "with open('/Users/nipunbhatia/Desktop/y4s1/dam/goodreads_books_poetry.json', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            record = json.loads(line)\n",
    "            data.append(record)\n",
    "        except json.JSONDecodeError:\n",
    "            pass  # Handle invalid lines if needed\n",
    "\n",
    "# Now 'data' contains a list of dictionaries, each representing a JSON object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['isbn', 'text_reviews_count', 'series', 'country_code', 'language_code',\n",
       "       'popular_shelves', 'asin', 'is_ebook', 'average_rating', 'kindle_asin',\n",
       "       'similar_books', 'description', 'format', 'link', 'authors',\n",
       "       'publisher', 'num_pages', 'publication_day', 'isbn13',\n",
       "       'publication_month', 'edition_information', 'publication_year', 'url',\n",
       "       'image_url', 'book_id', 'ratings_count', 'work_id', 'title',\n",
       "       'title_without_series'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>series</th>\n",
       "      <th>country_code</th>\n",
       "      <th>language_code</th>\n",
       "      <th>popular_shelves</th>\n",
       "      <th>asin</th>\n",
       "      <th>is_ebook</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>kindle_asin</th>\n",
       "      <th>...</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>edition_information</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>url</th>\n",
       "      <th>image_url</th>\n",
       "      <th>book_id</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_id</th>\n",
       "      <th>title</th>\n",
       "      <th>title_without_series</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '8', 'name': 'to-read'}, {'count': ...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>3.83</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>1887</td>\n",
       "      <td>https://www.goodreads.com/book/show/16037549-v...</td>\n",
       "      <td>https://images.gr-assets.com/books/1348176637m...</td>\n",
       "      <td>16037549</td>\n",
       "      <td>3</td>\n",
       "      <td>5212748</td>\n",
       "      <td>Vision of Sir Launfal and Other Poems</td>\n",
       "      <td>Vision of Sir Launfal and Other Poems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1942004192</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '228', 'name': 'to-read'}, {'count'...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>5.00</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>First</td>\n",
       "      <td>2015</td>\n",
       "      <td>https://www.goodreads.com/book/show/29065952-l...</td>\n",
       "      <td>https://images.gr-assets.com/books/1455198396m...</td>\n",
       "      <td>29065952</td>\n",
       "      <td>9</td>\n",
       "      <td>49294781</td>\n",
       "      <td>Louder Than Everything You Love</td>\n",
       "      <td>Louder Than Everything You Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '5', 'name': 'to-read'}, {'count': ...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>4.75</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2009</td>\n",
       "      <td>https://www.goodreads.com/book/show/15861988-i...</td>\n",
       "      <td>https://images.gr-assets.com/books/1346225281m...</td>\n",
       "      <td>15861988</td>\n",
       "      <td>8</td>\n",
       "      <td>21611807</td>\n",
       "      <td>Into Temptation</td>\n",
       "      <td>Into Temptation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0692265295</td>\n",
       "      <td>10</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '853', 'name': 'to-read'}, {'count'...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>3.95</td>\n",
       "      <td>B00SM9ITQS</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>2015</td>\n",
       "      <td>https://www.goodreads.com/book/show/24849837-n...</td>\n",
       "      <td>https://images.gr-assets.com/books/1423580531m...</td>\n",
       "      <td>24849837</td>\n",
       "      <td>27</td>\n",
       "      <td>44304270</td>\n",
       "      <td>Naked Soul: The Erotic Love Poems</td>\n",
       "      <td>Naked Soul: The Erotic Love Poems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '206', 'name': 'to-read'}, {'count'...</td>\n",
       "      <td></td>\n",
       "      <td>true</td>\n",
       "      <td>4.00</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>2000</td>\n",
       "      <td>https://www.goodreads.com/book/show/17729612-t...</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>17729612</td>\n",
       "      <td>13</td>\n",
       "      <td>24801816</td>\n",
       "      <td>The More Loving One</td>\n",
       "      <td>The More Loving One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36491</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '131', 'name': 'to-read'}, {'count'...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>4.55</td>\n",
       "      <td>B0076BTK2K</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.goodreads.com/book/show/13452060-r...</td>\n",
       "      <td>https://images.gr-assets.com/books/1328356634m...</td>\n",
       "      <td>13452060</td>\n",
       "      <td>10</td>\n",
       "      <td>18977757</td>\n",
       "      <td>Ramblings &amp; Rhymes: An Anthology of Poetry</td>\n",
       "      <td>Ramblings &amp; Rhymes: An Anthology of Poetry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36492</th>\n",
       "      <td>1609640101</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '15', 'name': 'to-read'}, {'count':...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>4.89</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>2011</td>\n",
       "      <td>https://www.goodreads.com/book/show/11066682-f...</td>\n",
       "      <td>https://images.gr-assets.com/books/1329313687m...</td>\n",
       "      <td>11066682</td>\n",
       "      <td>9</td>\n",
       "      <td>15987970</td>\n",
       "      <td>Field Work: Notes, Songs, Poems 1997-2010</td>\n",
       "      <td>Field Work: Notes, Songs, Poems 1997-2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36494</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '21', 'name': 'to-read'}, {'count':...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>4.92</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>2009</td>\n",
       "      <td>https://www.goodreads.com/book/show/6554908-at...</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>6554908</td>\n",
       "      <td>12</td>\n",
       "      <td>6747498</td>\n",
       "      <td>At night, the dead:</td>\n",
       "      <td>At night, the dead:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36504</th>\n",
       "      <td>1943977046</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '200', 'name': 'to-read'}, {'count'...</td>\n",
       "      <td></td>\n",
       "      <td>false</td>\n",
       "      <td>4.28</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "      <td>https://www.goodreads.com/book/show/28923921-c...</td>\n",
       "      <td>https://images.gr-assets.com/books/1455223614m...</td>\n",
       "      <td>28923921</td>\n",
       "      <td>17</td>\n",
       "      <td>46806042</td>\n",
       "      <td>Call Me by My Other Name</td>\n",
       "      <td>Call Me by My Other Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36509</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '2', 'name': 'poetry'}, {'count': '...</td>\n",
       "      <td>B004CYF8NY</td>\n",
       "      <td>true</td>\n",
       "      <td>5.00</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.goodreads.com/book/show/9874488-ta...</td>\n",
       "      <td>https://s.gr-assets.com/assets/nophoto/book/11...</td>\n",
       "      <td>9874488</td>\n",
       "      <td>1</td>\n",
       "      <td>14766173</td>\n",
       "      <td>Take Out from the Writer's Café</td>\n",
       "      <td>Take Out from the Writer's Café</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8393 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             isbn text_reviews_count series country_code language_code  \\\n",
       "0                                  1     []           US           eng   \n",
       "4      1942004192                  4     []           US           eng   \n",
       "6                                  3     []           US           eng   \n",
       "10     0692265295                 10     []           US           eng   \n",
       "17                                 1     []           US           eng   \n",
       "...           ...                ...    ...          ...           ...   \n",
       "36491                              5     []           US           eng   \n",
       "36492  1609640101                  5     []           US           eng   \n",
       "36494                              2     []           US           eng   \n",
       "36504  1943977046                  6     []           US           eng   \n",
       "36509                              1     []           US           eng   \n",
       "\n",
       "                                         popular_shelves        asin is_ebook  \\\n",
       "0      [{'count': '8', 'name': 'to-read'}, {'count': ...                false   \n",
       "4      [{'count': '228', 'name': 'to-read'}, {'count'...                false   \n",
       "6      [{'count': '5', 'name': 'to-read'}, {'count': ...                false   \n",
       "10     [{'count': '853', 'name': 'to-read'}, {'count'...                false   \n",
       "17     [{'count': '206', 'name': 'to-read'}, {'count'...                 true   \n",
       "...                                                  ...         ...      ...   \n",
       "36491  [{'count': '131', 'name': 'to-read'}, {'count'...                false   \n",
       "36492  [{'count': '15', 'name': 'to-read'}, {'count':...                false   \n",
       "36494  [{'count': '21', 'name': 'to-read'}, {'count':...                false   \n",
       "36504  [{'count': '200', 'name': 'to-read'}, {'count'...                false   \n",
       "36509  [{'count': '2', 'name': 'poetry'}, {'count': '...  B004CYF8NY     true   \n",
       "\n",
       "      average_rating kindle_asin  ... publication_month edition_information  \\\n",
       "0               3.83              ...                11                       \n",
       "4               5.00              ...                12               First   \n",
       "6               4.75              ...                                         \n",
       "10              3.95  B00SM9ITQS  ...                 1                       \n",
       "17              4.00              ...                10                       \n",
       "...              ...         ...  ...               ...                 ...   \n",
       "36491           4.55  B0076BTK2K  ...                 6                       \n",
       "36492           4.89              ...                 4                       \n",
       "36494           4.92              ...                 6                       \n",
       "36504           4.28              ...                 3                       \n",
       "36509           5.00              ...                                         \n",
       "\n",
       "      publication_year                                                url  \\\n",
       "0                 1887  https://www.goodreads.com/book/show/16037549-v...   \n",
       "4                 2015  https://www.goodreads.com/book/show/29065952-l...   \n",
       "6                 2009  https://www.goodreads.com/book/show/15861988-i...   \n",
       "10                2015  https://www.goodreads.com/book/show/24849837-n...   \n",
       "17                2000  https://www.goodreads.com/book/show/17729612-t...   \n",
       "...                ...                                                ...   \n",
       "36491             2011  https://www.goodreads.com/book/show/13452060-r...   \n",
       "36492             2011  https://www.goodreads.com/book/show/11066682-f...   \n",
       "36494             2009  https://www.goodreads.com/book/show/6554908-at...   \n",
       "36504             2016  https://www.goodreads.com/book/show/28923921-c...   \n",
       "36509                   https://www.goodreads.com/book/show/9874488-ta...   \n",
       "\n",
       "                                               image_url   book_id  \\\n",
       "0      https://images.gr-assets.com/books/1348176637m...  16037549   \n",
       "4      https://images.gr-assets.com/books/1455198396m...  29065952   \n",
       "6      https://images.gr-assets.com/books/1346225281m...  15861988   \n",
       "10     https://images.gr-assets.com/books/1423580531m...  24849837   \n",
       "17     https://s.gr-assets.com/assets/nophoto/book/11...  17729612   \n",
       "...                                                  ...       ...   \n",
       "36491  https://images.gr-assets.com/books/1328356634m...  13452060   \n",
       "36492  https://images.gr-assets.com/books/1329313687m...  11066682   \n",
       "36494  https://s.gr-assets.com/assets/nophoto/book/11...   6554908   \n",
       "36504  https://images.gr-assets.com/books/1455223614m...  28923921   \n",
       "36509  https://s.gr-assets.com/assets/nophoto/book/11...   9874488   \n",
       "\n",
       "      ratings_count   work_id                                       title  \\\n",
       "0                 3   5212748       Vision of Sir Launfal and Other Poems   \n",
       "4                 9  49294781             Louder Than Everything You Love   \n",
       "6                 8  21611807                             Into Temptation   \n",
       "10               27  44304270           Naked Soul: The Erotic Love Poems   \n",
       "17               13  24801816                         The More Loving One   \n",
       "...             ...       ...                                         ...   \n",
       "36491            10  18977757  Ramblings & Rhymes: An Anthology of Poetry   \n",
       "36492             9  15987970   Field Work: Notes, Songs, Poems 1997-2010   \n",
       "36494            12   6747498                         At night, the dead:   \n",
       "36504            17  46806042                    Call Me by My Other Name   \n",
       "36509             1  14766173             Take Out from the Writer's Café   \n",
       "\n",
       "                             title_without_series  \n",
       "0           Vision of Sir Launfal and Other Poems  \n",
       "4                 Louder Than Everything You Love  \n",
       "6                                 Into Temptation  \n",
       "10              Naked Soul: The Erotic Love Poems  \n",
       "17                            The More Loving One  \n",
       "...                                           ...  \n",
       "36491  Ramblings & Rhymes: An Anthology of Poetry  \n",
       "36492   Field Work: Notes, Songs, Poems 1997-2010  \n",
       "36494                         At night, the dead:  \n",
       "36504                    Call Me by My Other Name  \n",
       "36509             Take Out from the Writer's Café  \n",
       "\n",
       "[8393 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['language_code']=='eng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_books = len(df)\n",
    "\n",
    "# Set threshold frequencies for common and rare shelves\n",
    "common_threshold = 0.5  # 50%\n",
    "rare_threshold = 0.001  # 0.1%\n",
    "\n",
    "# Define a function to filter shelves\n",
    "def filter_shelves(shelf_list):\n",
    "    filtered_shelves = []\n",
    "    for shelf in shelf_list:\n",
    "        shelf_occurrence = int(shelf['count']) / total_books\n",
    "        if common_threshold >= shelf_occurrence >= rare_threshold:\n",
    "            filtered_shelves.append(shelf)\n",
    "    return filtered_shelves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                       []\n",
      "1                    [{'count': '100', 'name': 'to-read'}]\n",
      "2                                                       []\n",
      "3        [{'count': '554', 'name': 'to-read'}, {'count'...\n",
      "4                    [{'count': '228', 'name': 'to-read'}]\n",
      "                               ...                        \n",
      "36509                                                   []\n",
      "36510    [{'count': '1158', 'name': 'to-read'}, {'count...\n",
      "36511                                                   []\n",
      "36512    [{'count': '14252', 'name': 'classics'}, {'cou...\n",
      "36513                 [{'count': '37', 'name': 'to-read'}]\n",
      "Name: filtered_shelves, Length: 36514, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Apply the filter_shelves function to the 'shelves' column\n",
    "df['filtered_shelves'] = df['popular_shelves'].apply(filter_shelves)\n",
    "\n",
    "# Now 'filtered_shelves' column contains shelves that meet your filtering criteria\n",
    "print(df['filtered_shelves'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [{'count': '8', 'name': 'to-read'}, {'count': ...\n",
       "1        [{'count': '100', 'name': 'to-read'}, {'count'...\n",
       "2        [{'count': '32', 'name': 'to-read'}, {'count':...\n",
       "3        [{'count': '554', 'name': 'to-read'}, {'count'...\n",
       "4        [{'count': '228', 'name': 'to-read'}, {'count'...\n",
       "                               ...                        \n",
       "36509    [{'count': '2', 'name': 'poetry'}, {'count': '...\n",
       "36510    [{'count': '1158', 'name': 'to-read'}, {'count...\n",
       "36511                   [{'count': '3', 'name': 'poetry'}]\n",
       "36512    [{'count': '247044', 'name': 'to-read'}, {'cou...\n",
       "36513    [{'count': '37', 'name': 'to-read'}, {'count':...\n",
       "Name: popular_shelves, Length: 36514, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['popular_shelves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "36509    False\n",
       "36510    False\n",
       "36511    False\n",
       "36512    False\n",
       "36513    False\n",
       "Length: 36514, dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['filtered_shelves']==df['popular_shelves']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Number 30 in a series of literary pamphlets pu...\n",
       "1        Fairy Tales gathers the unconventional verse d...\n",
       "2        Three poems describe the nighttime adventures ...\n",
       "3        A modern verse play about the search for meani...\n",
       "4        Louder Than Everything You Love is about trans...\n",
       "                               ...                        \n",
       "36509    Appetizers\\n*Poetry- Acrostic\\nWo(Man)- Diaman...\n",
       "36510    There was an Old Derry down Derry, who loved t...\n",
       "36511                                                     \n",
       "36512    'Muse, tell me of a man: a man of much resourc...\n",
       "36513    Gathers poems by William Blake, Emily Bronte, ...\n",
       "Name: description, Length: 36514, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'author_id': '619932', 'role': ''}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['authors'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filtered_shelves_text'] = df['filtered_shelves'].apply(lambda x: ' '.join([shelf['name'] for shelf in x]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mfiltered_shelves_text\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['filtered_shelves_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Number 30 in a series of literary pamphlets pu...\n",
       "1        Fairy Tales gathers the unconventional verse d...\n",
       "2        Three poems describe the nighttime adventures ...\n",
       "3        A modern verse play about the search for meani...\n",
       "4        Louder Than Everything You Love is about trans...\n",
       "                               ...                        \n",
       "36509    Appetizers\\n*Poetry- Acrostic\\nWo(Man)- Diaman...\n",
       "36510    There was an Old Derry down Derry, who loved t...\n",
       "36511                                                     \n",
       "36512    'Muse, tell me of a man: a man of much resourc...\n",
       "36513    Gathers poems by William Blake, Emily Bronte, ...\n",
       "Name: description, Length: 36514, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Le poesie di Michelstaedter, finora troppo poco conosciute, ci fanno sentire, in un'altra forma, la stessa vibrazione estrema di La persuasione e la rettorica. Composte fra il 1905 e il 1910, risentono solo superficialmente del clima letterario italiano di quegli anni. Mentre subito vi affiorano quei temi ultimi a cui Michelstaedter dedico la sua riflessione filosofica: i temi di chi e mosso da un'invincibile vocazione a spingersi di la dal bordo della vita, <>. All'inizio con timbro adolescenziale, e ancora tenuto alla sudditanza verso temi obbligati, poi con un piglio sempre piu sicuro, e distaccandosi rapidamente da ogni dipendenza, Michelstaedter svela anche qui il suo dono specifico, quello dell'immediatezza nel pensiero, e ci guida <>attraverso un mare sempre piu aperto e pericoloso, il vero <>, un mare assente, rispetto al quale si puo dire che <>.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'][844]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].str.replace('-', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/t2rvlzw95m1b1vf1nr7yggxw0000gn/T/ipykernel_30941/3649175356.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['description'] = df['description'].str.replace('\\s+', ' ')\n"
     ]
    }
   ],
   "source": [
    "df['description'] = df['description'].str.replace('\\s+', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/t2rvlzw95m1b1vf1nr7yggxw0000gn/T/ipykernel_30941/2996925421.py:1: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['description'] = df['description'].str.replace('*', ' ')\n"
     ]
    }
   ],
   "source": [
    "df['description'] = df['description'].str.replace('*', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return 'unknown'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['detected_language'] = df['description'].apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en         63.534535\n",
      "unknown    20.698910\n",
      "cy          4.368188\n",
      "es          2.404557\n",
      "pt          1.043435\n",
      "it          1.029742\n",
      "tr          0.964014\n",
      "sl          0.569645\n",
      "fr          0.561428\n",
      "id          0.536780\n",
      "fi          0.495700\n",
      "nl          0.462836\n",
      "de          0.419017\n",
      "ro          0.345073\n",
      "sv          0.317686\n",
      "pl          0.293038\n",
      "et          0.238265\n",
      "sk          0.224571\n",
      "da          0.216355\n",
      "no          0.202662\n",
      "hr          0.194446\n",
      "sq          0.156105\n",
      "lt          0.147888\n",
      "so          0.142411\n",
      "vi          0.104070\n",
      "lv          0.093115\n",
      "cs          0.082160\n",
      "tl          0.054774\n",
      "sw          0.032864\n",
      "ca          0.027387\n",
      "af          0.024648\n",
      "hu          0.013693\n",
      "Name: detected_language, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "language_counts = df['detected_language'].value_counts()\n",
    "total_descriptions = len(df)\n",
    "\n",
    "# Calculate the percentage of descriptions in each language\n",
    "language_percentage = (language_counts / total_descriptions) * 100\n",
    "\n",
    "# Display the language distribution\n",
    "print(language_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23202.999853459998"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".63545489*(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36514"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             en\n",
       "1             en\n",
       "2             en\n",
       "3             en\n",
       "4             en\n",
       "          ...   \n",
       "36509         en\n",
       "36510         en\n",
       "36511    unknown\n",
       "36512         en\n",
       "36513         en\n",
       "Name: detected_language, Length: 36514, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['detected_language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named 'df'\n",
    "# You can filter it to select only English books like this:\n",
    "\n",
    "df_english = df[df['detected_language'] == 'en']\n",
    "\n",
    "# Now, 'df_english' contains only the rows where the language code is 'eng', which corresponds to English books.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23199"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Number 30 in a series of literary pamphlets pu...\n",
       "1        Fairy Tales gathers the unconventional verse d...\n",
       "2        Three poems describe the nighttime adventures ...\n",
       "3        A modern verse play about the search for meani...\n",
       "4        Louder Than Everything You Love is about trans...\n",
       "                               ...                        \n",
       "36509    Appetizers  Poetry Acrostic Wo(Man) Diamante U...\n",
       "36510    There was an Old Derry down Derry, who loved t...\n",
       "36511                                                     \n",
       "36512    'Muse, tell me of a man: a man of much resourc...\n",
       "36513    Gathers poems by William Blake, Emily Bronte, ...\n",
       "Name: description, Length: 36514, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Black Butterfly is a symbol of transformation and rebirth after death. Drake wrote this book for those who have lost someone in death and in life. This book is a collection of memories and experiences Drake lived after the death of one of his brothers. He promised he would write him a few words after he failed to complete the task while his brother was alive. This book is everything... this book is for all who are breathing and for all who are no longer here. This book is for you.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_english['description'][55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
    "    return lemmatized_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/t2rvlzw95m1b1vf1nr7yggxw0000gn/T/ipykernel_30941/2440208721.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_english['description'] = df_english['description'].apply(lemmatize_text)\n"
     ]
    }
   ],
   "source": [
    "# Apply lemmatization to the 'descriptions' column\n",
    "df_english['description'] = df_english['description'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['isbn', 'text_reviews_count', 'series', 'country_code', 'language_code',\n",
       "       'popular_shelves', 'asin', 'is_ebook', 'average_rating', 'kindle_asin',\n",
       "       'similar_books', 'description', 'format', 'link', 'authors',\n",
       "       'publisher', 'num_pages', 'publication_day', 'isbn13',\n",
       "       'publication_month', 'edition_information', 'publication_year', 'url',\n",
       "       'image_url', 'book_id', 'ratings_count', 'work_id', 'title',\n",
       "       'title_without_series', 'filtered_shelves', 'filtered_shelves_text',\n",
       "       'detected_language'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_english.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_english['authors'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/t2rvlzw95m1b1vf1nr7yggxw0000gn/T/ipykernel_30941/2522239205.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_english['combined_text'] = df_english['title'] + ' ' + df_english['description'] + ' ' + df['publication_year'].astype(str)+ ' ' + df_english['filtered_shelves_text']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'combined_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'combined_text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m df_english[\u001b[39m'\u001b[39m\u001b[39mcombined_text\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_english[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m df_english[\u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mpublication_year\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m df_english[\u001b[39m'\u001b[39m\u001b[39mfiltered_shelves_text\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[39m# Tokenize the combined_text column for training Word2Vec\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m tokenized_text \u001b[39m=\u001b[39m [text\u001b[39m.\u001b[39msplit() \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m df[\u001b[39m'\u001b[39;49m\u001b[39mcombined_text\u001b[39;49m\u001b[39m'\u001b[39;49m]]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'combined_text'"
     ]
    }
   ],
   "source": [
    "# Assuming 'df' is your DataFrame containing the features\n",
    "# Combine relevant textual features into a single column\n",
    "df_english['combined_text'] = df_english['title'] + ' ' + df_english['description'] + ' ' + df['publication_year'].astype(str)+ ' ' + df_english['filtered_shelves_text']\n",
    "\n",
    "# Tokenize the combined_text column for training Word2Vec\n",
    "tokenized_text = [text.split() for text in df_english['combined_text']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = [text.split() for text in df_english['combined_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the Word2Vec model\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(tokenized_text, vector_size=100, window=5, min_count=1, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Black Butterfly'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_english['title'][55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23199"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'Black Butterfly' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m user_input_vector \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mwv[\u001b[39m\"\u001b[39;49m\u001b[39mBlack Butterfly\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/gensim/models/keyedvectors.py:403\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \n\u001b[1;32m    391\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[0;32m--> 403\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_vector(key_or_keys)\n\u001b[1;32m    405\u001b[0m \u001b[39mreturn\u001b[39;00m vstack([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_vector(key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m key_or_keys])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/gensim/models/keyedvectors.py:446\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_vector\u001b[39m(\u001b[39mself\u001b[39m, key, norm\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    423\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \n\u001b[1;32m    425\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m \n\u001b[1;32m    445\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_index(key)\n\u001b[1;32m    447\u001b[0m     \u001b[39mif\u001b[39;00m norm:\n\u001b[1;32m    448\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_norms()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/gensim/models/keyedvectors.py:420\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m default\n\u001b[1;32m    419\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mKey \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not present\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'Black Butterfly' not present\""
     ]
    }
   ],
   "source": [
    "user_input_vector = model.wv[\"Black Butterfly\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',': 0,\n",
       " 'the': 1,\n",
       " 'of': 2,\n",
       " 'and': 3,\n",
       " '.': 4,\n",
       " 'a': 5,\n",
       " 'be': 6,\n",
       " 'in': 7,\n",
       " 'to': 8,\n",
       " '\"': 9,\n",
       " \"'s\": 10,\n",
       " 'poem': 11,\n",
       " 'as': 12,\n",
       " 'with': 13,\n",
       " 'his': 14,\n",
       " 'poetry': 15,\n",
       " 'that': 16,\n",
       " 'for': 17,\n",
       " 'this': 18,\n",
       " 'from': 19,\n",
       " 'by': 20,\n",
       " 'have': 21,\n",
       " 'on': 22,\n",
       " 'an': 23,\n",
       " 'to-read': 24,\n",
       " 'it': 25,\n",
       " 'poet': 26,\n",
       " 'he': 27,\n",
       " \"'\": 28,\n",
       " 'her': 29,\n",
       " 'book': 30,\n",
       " 'work': 31,\n",
       " 'we': 32,\n",
       " 'one': 33,\n",
       " 'collection': 34,\n",
       " ':': 35,\n",
       " 'I': 36,\n",
       " 'at': 37,\n",
       " ')': 38,\n",
       " 'life': 39,\n",
       " '(': 40,\n",
       " 'all': 41,\n",
       " 'they': 42,\n",
       " 'not': 43,\n",
       " 'love': 44,\n",
       " 'write': 45,\n",
       " 'you': 46,\n",
       " ';': 47,\n",
       " 'its': 48,\n",
       " 'these': 49,\n",
       " 'she': 50,\n",
       " 'but': 51,\n",
       " 'world': 52,\n",
       " 'most': 53,\n",
       " 'who': 54,\n",
       " 'or': 55,\n",
       " 'new': 56,\n",
       " 'into': 57,\n",
       " 'The': 58,\n",
       " 'their': 59,\n",
       " 'first': 60,\n",
       " 'Poems': 61,\n",
       " 'which': 62,\n",
       " 'time': 63,\n",
       " 'our': 64,\n",
       " 'include': 65,\n",
       " 'what': 66,\n",
       " 'about': 67,\n",
       " 'Poetry': 68,\n",
       " 'through': 69,\n",
       " 'will': 70,\n",
       " 'make': 71,\n",
       " 'reader': 72,\n",
       " 'other': 73,\n",
       " 'more': 74,\n",
       " 'year': 75,\n",
       " 'do': 76,\n",
       " '/': 77,\n",
       " 'language': 78,\n",
       " 'like': 79,\n",
       " 'story': 80,\n",
       " 'well': 81,\n",
       " 'great': 82,\n",
       " 'author': 83,\n",
       " 'can': 84,\n",
       " 'literature': 85,\n",
       " 'also': 86,\n",
       " 'many': 87,\n",
       " 'century': 88,\n",
       " 'currently-reading': 89,\n",
       " '?': 90,\n",
       " 'know': 91,\n",
       " 'translation': 92,\n",
       " 'verse': 93,\n",
       " 'edition': 94,\n",
       " 'own': 95,\n",
       " 'find': 96,\n",
       " 'classic': 97,\n",
       " 'publish': 98,\n",
       " 'both': 99,\n",
       " 'here': 100,\n",
       " 'when': 101,\n",
       " 'history': 102,\n",
       " 'american': 103,\n",
       " 'New': 104,\n",
       " 'word': 105,\n",
       " 'out': 106,\n",
       " 'volume': 107,\n",
       " 'each': 108,\n",
       " 'my': 109,\n",
       " 'take': 110,\n",
       " 'up': 111,\n",
       " 'between': 112,\n",
       " 'voice': 113,\n",
       " 'than': 114,\n",
       " 'how': 115,\n",
       " 'there': 116,\n",
       " 'way': 117,\n",
       " 'poetic': 118,\n",
       " 'read': 119,\n",
       " 'so': 120,\n",
       " 'fiction': 121,\n",
       " 'some': 122,\n",
       " 'where': 123,\n",
       " 'writer': 124,\n",
       " 'human': 125,\n",
       " 'literary': 126,\n",
       " 'form': 127,\n",
       " 'come': 128,\n",
       " 'your': 129,\n",
       " 'two': 130,\n",
       " 'favorites': 131,\n",
       " 'good': 132,\n",
       " 'live': 133,\n",
       " 'only': 134,\n",
       " 'experience': 135,\n",
       " '&': 136,\n",
       " 'such': 137,\n",
       " 'death': 138,\n",
       " 'classics': 139,\n",
       " 'long': 140,\n",
       " 'woman': 141,\n",
       " 'no': 142,\n",
       " 'Book': 143,\n",
       " 'over': 144,\n",
       " 'art': 145,\n",
       " 'man': 146,\n",
       " 'present': 147,\n",
       " 'place': 148,\n",
       " 'give': 149,\n",
       " 'original': 150,\n",
       " 'text': 151,\n",
       " 'contemporary': 152,\n",
       " 'bring': 153,\n",
       " 'play': 154,\n",
       " 'child': 155,\n",
       " 'writing': 156,\n",
       " 'see': 157,\n",
       " 'full': 158,\n",
       " 'after': 159,\n",
       " 'now': 160,\n",
       " 'introduction': 161,\n",
       " 'explore': 162,\n",
       " 'become': 163,\n",
       " 'English': 164,\n",
       " 'day': 165,\n",
       " 'say': 166,\n",
       " 'offer': 167,\n",
       " 'heart': 168,\n",
       " 'A': 169,\n",
       " 'part': 170,\n",
       " 'line': 171,\n",
       " 'while': 172,\n",
       " 'owned': 173,\n",
       " 'modern': 174,\n",
       " 'prose': 175,\n",
       " 'school': 176,\n",
       " 'epic': 177,\n",
       " '...': 178,\n",
       " '!': 179,\n",
       " 'if': 180,\n",
       " 'tell': 181,\n",
       " 'family': 182,\n",
       " 'win': 183,\n",
       " 'even': 184,\n",
       " 'go': 185,\n",
       " 'range': 186,\n",
       " 'self': 187,\n",
       " 'together': 188,\n",
       " 'young': 189,\n",
       " 'yet': 190,\n",
       " 'those': 191,\n",
       " 'people': 192,\n",
       " 'move': 193,\n",
       " 'just': 194,\n",
       " 'books-i-own': 195,\n",
       " 'use': 196,\n",
       " 'early': 197,\n",
       " 'page': 198,\n",
       " 'every': 199,\n",
       " 'war': 200,\n",
       " 'John': 201,\n",
       " 'historical': 202,\n",
       " 'never': 203,\n",
       " 'english': 204,\n",
       " 'create': 205,\n",
       " 'call': 206,\n",
       " 'personal': 207,\n",
       " 'series': 208,\n",
       " 'selection': 209,\n",
       " 'thing': 210,\n",
       " 'beauty': 211,\n",
       " 'much': 212,\n",
       " 'nature': 213,\n",
       " 'body': 214,\n",
       " 'Robert': 215,\n",
       " 'before': 216,\n",
       " 'back': 217,\n",
       " 'lyric': 218,\n",
       " 'America': 219,\n",
       " 'turn': 220,\n",
       " 'old': 221,\n",
       " 'anthology': 222,\n",
       " 'essay': 223,\n",
       " 'speak': 224,\n",
       " 'ever': 225,\n",
       " 'three': 226,\n",
       " 'Selected': 227,\n",
       " 'among': 228,\n",
       " 'begin': 229,\n",
       " 'power': 230,\n",
       " 'often': 231,\n",
       " '2013': 232,\n",
       " 'look': 233,\n",
       " 'short': 234,\n",
       " 'journey': 235,\n",
       " 'age': 236,\n",
       " 'Award': 237,\n",
       " 'beautiful': 238,\n",
       " 'Prize': 239,\n",
       " 'would': 240,\n",
       " 'note': 241,\n",
       " '2014': 242,\n",
       " 'whose': 243,\n",
       " 'moment': 244,\n",
       " 'theme': 245,\n",
       " 'culture': 246,\n",
       " 'contain': 247,\n",
       " 'last': 248,\n",
       " 'provide': 249,\n",
       " 'American': 250,\n",
       " 'light': 251,\n",
       " 'philosophy': 252,\n",
       " 'celebrate': 253,\n",
       " 'feel': 254,\n",
       " 'sense': 255,\n",
       " 'York': 256,\n",
       " '2012': 257,\n",
       " 'artist': 258,\n",
       " '2015': 259,\n",
       " 'ancient': 260,\n",
       " 'mind': 261,\n",
       " 'image': 262,\n",
       " 'loss': 263,\n",
       " 'leave': 264,\n",
       " 'bear': 265,\n",
       " 'once': 266,\n",
       " 'feature': 267,\n",
       " 'friend': 268,\n",
       " 'then': 269,\n",
       " 'narrative': 270,\n",
       " 'always': 271,\n",
       " 'around': 272,\n",
       " 'home': 273,\n",
       " 'inspire': 274,\n",
       " 'important': 275,\n",
       " '2009': 276,\n",
       " 'end': 277,\n",
       " 'very': 278,\n",
       " 'fantasy': 279,\n",
       " 'novel': 280,\n",
       " 'think': 281,\n",
       " 'to-buy': 282,\n",
       " 'song': 283,\n",
       " 'reveal': 284,\n",
       " 'mother': 285,\n",
       " 'classical': 286,\n",
       " 'any': 287,\n",
       " 'subject': 288,\n",
       " 'owned-books': 289,\n",
       " 'mythology': 290,\n",
       " 'spiritual': 291,\n",
       " 'twenty': 292,\n",
       " 'title': 293,\n",
       " 'memory': 294,\n",
       " 'tale': 295,\n",
       " 'show': 296,\n",
       " '2011': 297,\n",
       " 'music': 298,\n",
       " 'within': 299,\n",
       " 'past': 300,\n",
       " '2016': 301,\n",
       " 'again': 302,\n",
       " '2010': 303,\n",
       " 'dream': 304,\n",
       " 'landscape': 305,\n",
       " 'open': 306,\n",
       " 'set': 307,\n",
       " 'letter': 308,\n",
       " 'capture': 309,\n",
       " 'myth': 310,\n",
       " 'library': 311,\n",
       " 'default': 312,\n",
       " 'tradition': 313,\n",
       " 'get': 314,\n",
       " 'follow': 315,\n",
       " 'still': 316,\n",
       " 'want': 317,\n",
       " 'draw': 318,\n",
       " 'since': 319,\n",
       " 'name': 320,\n",
       " 'eye': 321,\n",
       " 'face': 322,\n",
       " 'relationship': 323,\n",
       " 'powerful': 324,\n",
       " 'may': 325,\n",
       " 'during': 326,\n",
       " 'lose': 327,\n",
       " 'appear': 328,\n",
       " 'illustration': 329,\n",
       " 'Love': 330,\n",
       " 'four': 331,\n",
       " 'change': 332,\n",
       " 'deep': 333,\n",
       " 'winner': 334,\n",
       " 'lover': 335,\n",
       " 'question': 336,\n",
       " 'rich': 337,\n",
       " 'sometimes': 338,\n",
       " 'drama': 339,\n",
       " '2008': 340,\n",
       " 'unique': 341,\n",
       " 'mean': 342,\n",
       " 'second': 343,\n",
       " 'award': 344,\n",
       " 'character': 345,\n",
       " 'vision': 346,\n",
       " 'University': 347,\n",
       " 'generation': 348,\n",
       " '2007': 349,\n",
       " 'political': 350,\n",
       " 'William': 351,\n",
       " 'translate': 352,\n",
       " 'down': 353,\n",
       " 'style': 354,\n",
       " 'Shakespeare': 355,\n",
       " 'too': 356,\n",
       " 'greek': 357,\n",
       " 'hope': 358,\n",
       " 'describe': 359,\n",
       " 'another': 360,\n",
       " 'little': 361,\n",
       " 'lead': 362,\n",
       " 'adult': 363,\n",
       " 'college': 364,\n",
       " 'today': 365,\n",
       " 'complete': 366,\n",
       " 'favourites': 367,\n",
       " 'something': 368,\n",
       " 'humor': 369,\n",
       " 'famous': 370,\n",
       " 'small': 371,\n",
       " 'same': 372,\n",
       " 'piece': 373,\n",
       " 'debut': 374,\n",
       " 'major': 375,\n",
       " 'War': 376,\n",
       " 'continue': 377,\n",
       " 'imagination': 378,\n",
       " '2006': 379,\n",
       " 'father': 380,\n",
       " 'late': 381,\n",
       " 'against': 382,\n",
       " 'dark': 383,\n",
       " 'lyrical': 384,\n",
       " 'spirit': 385,\n",
       " 'hand': 386,\n",
       " 'city': 387,\n",
       " 'desire': 388,\n",
       " 'God': 389,\n",
       " 'five': 390,\n",
       " 'itself': 391,\n",
       " 'World': 392,\n",
       " 'himself': 393,\n",
       " 'grow': 394,\n",
       " 'travel': 395,\n",
       " 'fall': 396,\n",
       " 'adventure': 397,\n",
       " '2005': 398,\n",
       " 'cover': 399,\n",
       " 'throughout': 400,\n",
       " 'joy': 401,\n",
       " 'student': 402,\n",
       " 'available': 403,\n",
       " 'reading': 404,\n",
       " 'fine': 405,\n",
       " 'consider': 406,\n",
       " 'true': 407,\n",
       " 'could': 408,\n",
       " 'kind': 409,\n",
       " 'passion': 410,\n",
       " 'soul': 411,\n",
       " 'along': 412,\n",
       " 'reflect': 413,\n",
       " 'without': 414,\n",
       " 'David': 415,\n",
       " 'novels': 416,\n",
       " 'Review': 417,\n",
       " 'editor': 418,\n",
       " 'share': 419,\n",
       " 'later': 420,\n",
       " 'rhyme': 421,\n",
       " 'version': 422,\n",
       " 'figure': 423,\n",
       " 'hold': 424,\n",
       " 'help': 425,\n",
       " 'across': 426,\n",
       " 'under': 427,\n",
       " 'select': 428,\n",
       " '2004': 429,\n",
       " 'girl': 430,\n",
       " 'classics-to-read': 431,\n",
       " 'kindle': 432,\n",
       " 'natural': 433,\n",
       " 'struggle': 434,\n",
       " 'childhood': 435,\n",
       " 'my-library': 436,\n",
       " 'religion': 437,\n",
       " 'influence': 438,\n",
       " 'de': 439,\n",
       " 'non-fiction': 440,\n",
       " 'classic-literature': 441,\n",
       " 'for-school': 442,\n",
       " 'read-for-school': 443,\n",
       " 'must': 444,\n",
       " 'high': 445,\n",
       " 'stand': 446,\n",
       " 'meaning': 447,\n",
       " 'everything': 448,\n",
       " 'free': 449,\n",
       " 'because': 450,\n",
       " 'study': 451,\n",
       " 'force': 452,\n",
       " 'remarkable': 453,\n",
       " 'die': 454,\n",
       " 'few': 455,\n",
       " 'illustrate': 456,\n",
       " 'seek': 457,\n",
       " 'truth': 458,\n",
       " 'section': 459,\n",
       " 'different': 460,\n",
       " 'sonnet': 461,\n",
       " 'funny': 462,\n",
       " 'cultural': 463,\n",
       " 'remain': 464,\n",
       " 'print': 465,\n",
       " 'need': 466,\n",
       " 'religious': 467,\n",
       " 'rory-gilmore-reading-challenge': 468,\n",
       " 'rory-gilmore-challenge': 469,\n",
       " 'to-read-classics': 470,\n",
       " 'twentieth': 471,\n",
       " 'off': 472,\n",
       " 'own-it': 473,\n",
       " 'scholar': 474,\n",
       " 'whether': 475,\n",
       " 'wit': 476,\n",
       " 'night': 477,\n",
       " 'color': 478,\n",
       " 'wide': 479,\n",
       " 'deeply': 480,\n",
       " 'beloved': 481,\n",
       " 'translator': 482,\n",
       " 'black': 483,\n",
       " 'break': 484,\n",
       " 'National': 485,\n",
       " 'thought': 486,\n",
       " 'James': 487,\n",
       " 'Press': 488,\n",
       " 'rory-gilmore-reading-list': 489,\n",
       " 'extraordinary': 490,\n",
       " 'far': 491,\n",
       " '2001': 492,\n",
       " 'real': 493,\n",
       " 'Collected': 494,\n",
       " 'upon': 495,\n",
       " 'Dickinson': 496,\n",
       " 'collect': 497,\n",
       " 'mystery': 498,\n",
       " 'discover': 499,\n",
       " 'learn': 500,\n",
       " 'seem': 501,\n",
       " 'Dante': 502,\n",
       " 'high-school': 503,\n",
       " '2002': 504,\n",
       " 'popular': 505,\n",
       " 'gift': 506,\n",
       " 'country': 507,\n",
       " 'masterpiece': 508,\n",
       " 'intimate': 509,\n",
       " 'hear': 510,\n",
       " 'Poets': 511,\n",
       " 'pleasure': 512,\n",
       " ']': 513,\n",
       " 'insight': 514,\n",
       " 'meditation': 515,\n",
       " '2017': 516,\n",
       " 'historical-fiction': 517,\n",
       " 'beyond': 518,\n",
       " 'space': 519,\n",
       " 'keep': 520,\n",
       " 'view': 521,\n",
       " '2003': 522,\n",
       " 'classic-fiction': 523,\n",
       " 'Other': 524,\n",
       " 'wonder': 525,\n",
       " 'return': 526,\n",
       " 'event': 527,\n",
       " 'social': 528,\n",
       " 'idea': 529,\n",
       " 'ebook': 530,\n",
       " 'represent': 531,\n",
       " 'pain': 532,\n",
       " 'search': 533,\n",
       " 'might': 534,\n",
       " 'Poet': 535,\n",
       " 'fill': 536,\n",
       " 'Emily': 537,\n",
       " 'favorite': 538,\n",
       " 'identity': 539,\n",
       " 'i-own': 540,\n",
       " 'my-books': 541,\n",
       " 'though': 542,\n",
       " 'familiar': 543,\n",
       " 'brilliant': 544,\n",
       " 'meet': 545,\n",
       " 'publication': 546,\n",
       " 'emotional': 547,\n",
       " 'tragedy': 548,\n",
       " 'whole': 549,\n",
       " 'home-library': 550,\n",
       " 'right': 551,\n",
       " 'Thomas': 552,\n",
       " 'teach': 553,\n",
       " 'point': 554,\n",
       " 'emotion': 555,\n",
       " 'feeling': 556,\n",
       " 'animal': 557,\n",
       " 'rory-gilmore': 558,\n",
       " 'sound': 559,\n",
       " 'detail': 560,\n",
       " 'hundred': 561,\n",
       " 'school-books': 562,\n",
       " 'away': 563,\n",
       " 'decade': 564,\n",
       " 'themselves': 565,\n",
       " 'career': 566,\n",
       " 'romance': 567,\n",
       " 'almost': 568,\n",
       " 'fresh': 569,\n",
       " 'Hamlet': 570,\n",
       " 'challenge': 571,\n",
       " 'close': 572,\n",
       " '2000': 573,\n",
       " 'introduce': 574,\n",
       " 'profound': 575,\n",
       " 'guide': 576,\n",
       " 'craft': 577,\n",
       " 'land': 578,\n",
       " 'master': 579,\n",
       " 'ask': 580,\n",
       " 'City': 581,\n",
       " 'try': 582,\n",
       " 'epic-poetry': 583,\n",
       " 'Times': 584,\n",
       " 'Whitman': 585,\n",
       " '[': 586,\n",
       " 'understand': 587,\n",
       " 'grief': 588,\n",
       " 'shape': 589,\n",
       " 'large': 590,\n",
       " 'perfect': 591,\n",
       " 'simple': 592,\n",
       " 'Paul': 593,\n",
       " 'Black': 594,\n",
       " 'vivid': 595,\n",
       " 'medieval': 596,\n",
       " 'touch': 597,\n",
       " 'base': 598,\n",
       " 'classic-lit': 599,\n",
       " 'matter': 600,\n",
       " 'sequence': 601,\n",
       " 'individual': 602,\n",
       " 'encounter': 603,\n",
       " 'Michael': 604,\n",
       " 'everyday': 605,\n",
       " 'the-classics': 606,\n",
       " 'school-reading': 607,\n",
       " 'school-reads': 608,\n",
       " 'order': 609,\n",
       " 'haiku': 610,\n",
       " 'result': 611,\n",
       " 'gilmore-girls': 612,\n",
       " 'murder': 613,\n",
       " 'rhythm': 614,\n",
       " 'Homer': 615,\n",
       " 'walk': 616,\n",
       " 'several': 617,\n",
       " 'marriage': 618,\n",
       " 'essential': 619,\n",
       " '1999': 620,\n",
       " 'critical': 621,\n",
       " 'delight': 622,\n",
       " 'Charles': 623,\n",
       " 'mark': 624,\n",
       " 'perhaps': 625,\n",
       " 'picture': 626,\n",
       " 'Eliot': 627,\n",
       " 'reality': 628,\n",
       " 'let': 629,\n",
       " 'why': 630,\n",
       " 'exploration': 631,\n",
       " 'address': 632,\n",
       " 'six': 633,\n",
       " 'half': 634,\n",
       " 'until': 635,\n",
       " 'unfinished': 636,\n",
       " '1998': 637,\n",
       " 'Mary': 638,\n",
       " 'portrait': 639,\n",
       " 'hard': 640,\n",
       " 'praise': 641,\n",
       " 'critic': 642,\n",
       " 'lit': 643,\n",
       " 'british': 644,\n",
       " 'movement': 645,\n",
       " 'creative': 646,\n",
       " 'edit': 647,\n",
       " 'wife': 648,\n",
       " 'scene': 649,\n",
       " 'romantic': 650,\n",
       " 'passionate': 651,\n",
       " 'clear': 652,\n",
       " 'attention': 653,\n",
       " 'focus': 654,\n",
       " 'combine': 655,\n",
       " 'violence': 656,\n",
       " 'understanding': 657,\n",
       " 'highly': 658,\n",
       " 'choose': 659,\n",
       " 'translated': 660,\n",
       " 'Best': 661,\n",
       " 'attempt': 662,\n",
       " 'teacher': 663,\n",
       " 'haunt': 664,\n",
       " 'imagery': 665,\n",
       " 'wisdom': 666,\n",
       " 'illuminate': 667,\n",
       " 'star': 668,\n",
       " 'nothing': 669,\n",
       " 'dead': 670,\n",
       " 'side': 671,\n",
       " 'period': 672,\n",
       " 'commentary': 673,\n",
       " 'depth': 674,\n",
       " 'fear': 675,\n",
       " 'should': 676,\n",
       " 'traditional': 677,\n",
       " 'widely': 678,\n",
       " 'inside': 679,\n",
       " 'reach': 680,\n",
       " 'quality': 681,\n",
       " 'issue': 682,\n",
       " 'Anthology': 683,\n",
       " 'imagine': 684,\n",
       " 'sing': 685,\n",
       " 'emerge': 686,\n",
       " 'complex': 687,\n",
       " 'state': 688,\n",
       " 'compose': 689,\n",
       " 'thousand': 690,\n",
       " 'plays': 691,\n",
       " 'express': 692,\n",
       " 'believe': 693,\n",
       " 'single': 694,\n",
       " 'Poe': 695,\n",
       " 'act': 696,\n",
       " 'process': 697,\n",
       " 'concern': 698,\n",
       " 'celebration': 699,\n",
       " 'bookshelf': 700,\n",
       " 'Young': 701,\n",
       " 'Song': 702,\n",
       " 'put': 703,\n",
       " 'sea': 704,\n",
       " 'date': 705,\n",
       " 'behind': 706,\n",
       " 'strange': 707,\n",
       " 'accessible': 708,\n",
       " 'variety': 709,\n",
       " 'beautifully': 710,\n",
       " 'antiquity': 711,\n",
       " 'horror': 712,\n",
       " 'final': 713,\n",
       " 'stunning': 714,\n",
       " 'inspiration': 715,\n",
       " 'boy': 716,\n",
       " 'Life': 717,\n",
       " 'adult-fiction': 718,\n",
       " 'course': 719,\n",
       " 'acclaim': 720,\n",
       " 'third': 721,\n",
       " 'ebooks': 722,\n",
       " \"'ve\": 723,\n",
       " 'Books': 724,\n",
       " 'source': 725,\n",
       " 'wish-list': 726,\n",
       " 'required-reading': 727,\n",
       " 'public': 728,\n",
       " 'to-re-read': 729,\n",
       " 'hero': 730,\n",
       " 'read-in-school': 731,\n",
       " 'knowledge': 732,\n",
       " 'gather': 733,\n",
       " 'genre': 734,\n",
       " 'accompany': 735,\n",
       " 'less': 736,\n",
       " 'Smith': 737,\n",
       " 'philosophical': 738,\n",
       " 'recent': 739,\n",
       " 'length': 740,\n",
       " 'audiobook': 741,\n",
       " 'native': 742,\n",
       " 'painting': 743,\n",
       " 'Iliad': 744,\n",
       " '1997': 745,\n",
       " 'enjoy': 746,\n",
       " 'toward': 747,\n",
       " 'thirty': 748,\n",
       " 'epics': 749,\n",
       " 'examine': 750,\n",
       " 'poems': 751,\n",
       " 'run': 752,\n",
       " 'rise': 753,\n",
       " 'witty': 754,\n",
       " 'produce': 755,\n",
       " 'design': 756,\n",
       " 'university': 757,\n",
       " 'alive': 758,\n",
       " 'Hughes': 759,\n",
       " 'rare': 760,\n",
       " 'society': 761,\n",
       " 're-read': 762,\n",
       " 'anyone': 763,\n",
       " 'future': 764,\n",
       " 'earth': 765,\n",
       " 'compelling': 766,\n",
       " 'herself': 767,\n",
       " 'various': 768,\n",
       " 'King': 769,\n",
       " 'longing': 770,\n",
       " 'record': 771,\n",
       " 'son': 772,\n",
       " 'community': 773,\n",
       " 'white': 774,\n",
       " 'sister': 775,\n",
       " 'daughter': 776,\n",
       " 'receive': 777,\n",
       " 'friendship': 778,\n",
       " 'seven': 779,\n",
       " 'fact': 780,\n",
       " 'house': 781,\n",
       " 'audience': 782,\n",
       " 'playful': 783,\n",
       " 'remember': 784,\n",
       " 'serve': 785,\n",
       " 'bird': 786,\n",
       " 'perspective': 787,\n",
       " 'sex': 788,\n",
       " 'Complete': 789,\n",
       " 'wild': 790,\n",
       " 'alone': 791,\n",
       " 'allow': 792,\n",
       " 'tree': 793,\n",
       " 'account': 794,\n",
       " 'lie': 795,\n",
       " 'universal': 796,\n",
       " 'grace': 797,\n",
       " 'addition': 798,\n",
       " 'god': 799,\n",
       " 'Williams': 800,\n",
       " 'speaker': 801,\n",
       " '1996': 802,\n",
       " 'happen': 803,\n",
       " 'remind': 804,\n",
       " 'transform': 805,\n",
       " 'tender': 806,\n",
       " 'person': 807,\n",
       " 'ghost': 808,\n",
       " 'Elizabeth': 809,\n",
       " 'to-reread': 810,\n",
       " 'performance': 811,\n",
       " 'group': 812,\n",
       " 'element': 813,\n",
       " 'reflection': 814,\n",
       " 'evoke': 815,\n",
       " 'span': 816,\n",
       " 'England': 817,\n",
       " 'context': 818,\n",
       " 'number': 819,\n",
       " 'recognize': 820,\n",
       " 'water': 821,\n",
       " 'originally': 822,\n",
       " 'Richard': 823,\n",
       " 'Rilke': 824,\n",
       " 'material': 825,\n",
       " 'expression': 826,\n",
       " 'add': 827,\n",
       " 'deal': 828,\n",
       " 'House': 829,\n",
       " 'elegy': 830,\n",
       " 'An': 831,\n",
       " 'journal': 832,\n",
       " 'dramatic': 833,\n",
       " 'interest': 834,\n",
       " 'clàssics': 835,\n",
       " 'italian': 836,\n",
       " 'energy': 837,\n",
       " 'possibility': 838,\n",
       " 'start': 839,\n",
       " 'memoir': 840,\n",
       " 'copy': 841,\n",
       " 'Rumi': 842,\n",
       " '1995': 843,\n",
       " 'particular': 844,\n",
       " 'endure': 845,\n",
       " 'ten': 846,\n",
       " 'previous': 847,\n",
       " 'survive': 848,\n",
       " 'root': 849,\n",
       " 'legend': 850,\n",
       " '100': 851,\n",
       " 'nearly': 852,\n",
       " 'Frost': 853,\n",
       " 'photograph': 854,\n",
       " 'United': 855,\n",
       " 'forget': 856,\n",
       " 'nonfiction': 857,\n",
       " 'Library': 858,\n",
       " 'head': 859,\n",
       " 'My': 860,\n",
       " 'West': 861,\n",
       " 'faith': 862,\n",
       " 'french': 863,\n",
       " 'all-time-favorites': 864,\n",
       " 'Edward': 865,\n",
       " 'Plath': 866,\n",
       " 'politic': 867,\n",
       " 'Pulitzer': 868,\n",
       " 'especially': 869,\n",
       " 's': 870,\n",
       " 'cat': 871,\n",
       " 'erotic': 872,\n",
       " 'S.': 873,\n",
       " 'theater': 874,\n",
       " 'connection': 875,\n",
       " 'influential': 876,\n",
       " 'daily': 877,\n",
       " 'secret': 878,\n",
       " 'George': 879,\n",
       " 'existence': 880,\n",
       " 'poignant': 881,\n",
       " 'battle': 882,\n",
       " 'engage': 883,\n",
       " 'Blake': 884,\n",
       " 'blue': 885,\n",
       " 'invite': 886,\n",
       " 'Series': 887,\n",
       " 'truly': 888,\n",
       " 'fire': 889,\n",
       " 'finally': 890,\n",
       " 'physical': 891,\n",
       " 'answer': 892,\n",
       " 'Night': 893,\n",
       " 'observation': 894,\n",
       " 'classical-literature': 895,\n",
       " 'chapter': 896,\n",
       " '1994': 897,\n",
       " 'Man': 898,\n",
       " 'previously': 899,\n",
       " 'imaginative': 900,\n",
       " 'Green': 901,\n",
       " 'genius': 902,\n",
       " 'Songs': 903,\n",
       " 'confront': 904,\n",
       " 'Jack': 905,\n",
       " 'ground': 906,\n",
       " 'Yeats': 907,\n",
       " 'example': 908,\n",
       " 'general': 909,\n",
       " 'season': 910,\n",
       " 'rather': 911,\n",
       " 'consciousness': 912,\n",
       " 'witness': 913,\n",
       " 'field': 914,\n",
       " 'fifty': 915,\n",
       " 'street': 916,\n",
       " 'dog': 917,\n",
       " 'drawing': 918,\n",
       " 'christian': 919,\n",
       " 'States': 920,\n",
       " 'film': 921,\n",
       " 'companion': 922,\n",
       " 'personal-library': 923,\n",
       " 'whom': 924,\n",
       " 'weave': 925,\n",
       " 'special': 926,\n",
       " 'ancient-literature': 927,\n",
       " 'ancient-history': 928,\n",
       " 'approach': 929,\n",
       " 'tone': 930,\n",
       " 'render': 931,\n",
       " 'above': 932,\n",
       " 'build': 933,\n",
       " 'fun': 934,\n",
       " 'Lee': 935,\n",
       " 'nation': 936,\n",
       " 'talk': 937,\n",
       " 'establish': 938,\n",
       " 'First': 939,\n",
       " 'strong': 940,\n",
       " 'western': 941,\n",
       " 'intense': 942,\n",
       " 'stage': 943,\n",
       " 'literary-fiction': 944,\n",
       " 'role': 945,\n",
       " 'diverse': 946,\n",
       " 'Troy': 947,\n",
       " 'W.': 948,\n",
       " 'wonderful': 949,\n",
       " 'ordinary': 950,\n",
       " 'comprehensive': 951,\n",
       " 'japanese': 952,\n",
       " 'eight': 953,\n",
       " 'carry': 954,\n",
       " 'brother': 955,\n",
       " 'trace': 956,\n",
       " 'biography': 957,\n",
       " 'blood': 958,\n",
       " 'practice': 959,\n",
       " 're': 960,\n",
       " 'visit': 961,\n",
       " 'fully': 962,\n",
       " 'possible': 963,\n",
       " 'brief': 964,\n",
       " 'freedom': 965,\n",
       " 'fan': 966,\n",
       " 'humanity': 967,\n",
       " 'Mark': 968,\n",
       " 'define': 969,\n",
       " 'talent': 970,\n",
       " 'humorous': 971,\n",
       " 'roman': 972,\n",
       " 'next': 973,\n",
       " 'Anne': 974,\n",
       " 'audio': 975,\n",
       " 'Old': 976,\n",
       " 'content': 977,\n",
       " 'visual': 978,\n",
       " 'fragment': 979,\n",
       " 'town': 980,\n",
       " 'lifetime': 981,\n",
       " 'Literature': 982,\n",
       " 'embrace': 983,\n",
       " 'Poem': 984,\n",
       " 'regard': 985,\n",
       " 'exist': 986,\n",
       " 'reference': 987,\n",
       " 'big': 988,\n",
       " 'stop': 989,\n",
       " 'quiet': 990,\n",
       " 'nine': 991,\n",
       " 'formal': 992,\n",
       " 'enough': 993,\n",
       " 'enter': 994,\n",
       " 'sorrow': 995,\n",
       " 'science': 996,\n",
       " 'aspect': 997,\n",
       " 'spend': 998,\n",
       " 'structure': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Combine the features into a single text feature\n",
    "df['combined_features'] = df['title'] + ' ' + df['description'] + ' ' + df['publication_year'].astype(str) + ' ' + df['filtered_shelves_text']\n",
    "\n",
    "# Initialize a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=5, stop_words='english')\n",
    "\n",
    "# Create the TF-IDF matrix for the combined text feature\n",
    "tfidf_matrix_combined = tfidf_vectorizer.fit_transform(df['combined_features'])\n",
    "\n",
    "# tfidf_matrix_combined now contains the TF-IDF representation of all four features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<36514x78698 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2422687 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming user_profile is a TF-IDF vector representing the user's preferences\n",
    "user_profile = tfidf_vectorizer.transform([\"Cornflakes\"])\n",
    "\n",
    "# Calculate cosine similarities between the user profile and all books\n",
    "similarities = cosine_similarity(user_profile, tfidf_matrix_combined)\n",
    "\n",
    "# Get the indices of books sorted by similarity (descending order)\n",
    "similar_indices = similarities[0].argsort()[::-1]\n",
    "\n",
    "# Recommend the top N books\n",
    "N = 10\n",
    "top_N_books = similar_indices[:N]\n",
    "\n",
    "# Display or return the recommended books\n",
    "recommended_books = df.iloc[top_N_books]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['isbn', 'text_reviews_count', 'series', 'country_code', 'language_code',\n",
       "       'popular_shelves', 'asin', 'is_ebook', 'average_rating', 'kindle_asin',\n",
       "       'similar_books', 'description', 'format', 'link', 'authors',\n",
       "       'publisher', 'num_pages', 'publication_day', 'isbn13',\n",
       "       'publication_month', 'edition_information', 'publication_year', 'url',\n",
       "       'image_url', 'book_id', 'ratings_count', 'work_id', 'title',\n",
       "       'title_without_series', 'filtered_shelves', 'filtered_shelves_text',\n",
       "       'detected_language'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_english.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36513           The Children's Classic Poetry Collection\n",
       "12169                                              Frogs\n",
       "12175                     The Winged Seed: A Remembrance\n",
       "12174                                             Odisea\n",
       "12173                                             Ilíada\n",
       "12172                                I canti di Maldoror\n",
       "12171    Sappho: A New Translation of the Complete Works\n",
       "12170                           The Pilgrim and The Star\n",
       "12168                                More Money than God\n",
       "12177                               Poems by Anne Bronte\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_books['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the TF-IDF matrix\n",
    "joblib.dump(tfidf_matrix_combined, 'tfidf_matrix.pkl')\n",
    "\n",
    "# Later, when you want to load it\n",
    "loaded_tfidf_matrix = joblib.load('tfidf_matrix.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<36514x78698 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2422687 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<36514x78698 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2422687 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "# Individual TF-IDF for Description\n",
    "tfidf_description = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\n",
    "tfidf_matrix_description = tfidf_description.fit_transform(df_english['description'])\n",
    "tfidf_matrix_description = normalize(tfidf_matrix_description, axis=1)  # Normalize TF-IDF matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23205x891117 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2748476 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual TF-IDF for Niche Shelves\n",
    "\n",
    "tfidf_niche_shelves = TfidfVectorizer(analyzer='word', min_df=0, stop_words='english')\n",
    "tfidf_matrix_niche_shelves = tfidf_niche_shelves.fit_transform(df_english['filtered_shelves_text'])\n",
    "tfidf_matrix_niche_shelves = normalize(tfidf_matrix_niche_shelves, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23205x401 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 105555 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix_niche_shelves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'author_id': '302994', 'role': ''}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_english['authors'][62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1887\n",
       "1        2015\n",
       "2        2008\n",
       "3        1964\n",
       "4        2015\n",
       "         ... \n",
       "36507    2001\n",
       "36509        \n",
       "36510        \n",
       "36512    2013\n",
       "36513    1996\n",
       "Name: publication_year, Length: 23203, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_english['publication_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/t2rvlzw95m1b1vf1nr7yggxw0000gn/T/ipykernel_8228/4252361467.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_english['Pub_Year_Title'] = df_english['publication_year'].astype(str) + ' ' + df_english['title']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_english['Pub_Year_Title'] = df_english['publication_year'].astype(str) + ' ' + df_english['title']\n",
    "\n",
    "# Common TF-IDF for Publication Year and Title\n",
    "tfidf_pub_year_title = TfidfVectorizer(analyzer='word', min_df=0, stop_words='english')\n",
    "tfidf_matrix_common = tfidf_pub_year_title.fit_transform(df_english['Pub_Year_Title'])\n",
    "tfidf_matrix_common= normalize(tfidf_matrix_common, axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23205x14494 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 91665 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Save each TF-IDF matrix to a separate file\n",
    "np.save('tfidf_matrix_description.npy', tfidf_matrix_description)\n",
    "np.save('tfidf_matrix_niche_shelves.npy', tfidf_matrix_niche_shelves)\n",
    "np.save('tfidf_matrix_common.npy', tfidf_matrix_common)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "()\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix_description.shape)\n",
    "print(tfidf_matrix_niche_shelves.shape)\n",
    "print(tfidf_matrix_common.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Load the TF-IDF matrices from the saved files\u001b[39;00m\n\u001b[1;32m      3\u001b[0m tfidf_matrix_description \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39m/Users/nipunbhatia/Desktop/y4s1/dam/tfidf_matrix_common.npy\u001b[39m\u001b[39m'\u001b[39m,allow_pickle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m tfidf_matrix_niche_shelves \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mtfidf_matrix_niche_shelves.npy\u001b[39;49m\u001b[39m'\u001b[39;49m,)\n\u001b[1;32m      6\u001b[0m tfidf_matrix_common \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mtfidf_matrix_common.npy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/lib/npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mopen_memmap(file, mode\u001b[39m=\u001b[39mmmap_mode,\n\u001b[1;32m    430\u001b[0m                                   max_header_size\u001b[39m=\u001b[39mmax_header_size)\n\u001b[1;32m    431\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 432\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(fid, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[1;32m    433\u001b[0m                                  pickle_kwargs\u001b[39m=\u001b[39;49mpickle_kwargs,\n\u001b[1;32m    434\u001b[0m                                  max_header_size\u001b[39m=\u001b[39;49mmax_header_size)\n\u001b[1;32m    435\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/lib/format.py:776\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[39mif\u001b[39;00m dtype\u001b[39m.\u001b[39mhasobject:\n\u001b[1;32m    774\u001b[0m     \u001b[39m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n\u001b[0;32m--> 776\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mObject arrays cannot be loaded when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    777\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mallow_pickle=False\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    778\u001b[0m     \u001b[39mif\u001b[39;00m pickle_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m         pickle_kwargs \u001b[39m=\u001b[39m {}\n",
      "\u001b[0;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Load the TF-IDF matrices from the saved files\n",
    "tfidf_matrix_description = np.load('/Users/nipunbhatia/Desktop/y4s1/dam/tfidf_matrix_common.npy',allow_pickle=True)\n",
    "\n",
    "tfidf_matrix_niche_shelves = np.load('tfidf_matrix_niche_shelves.npy',)\n",
    "tfidf_matrix_common = np.load('tfidf_matrix_common.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<23205x14494 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 91665 stored elements in Compressed Sparse Row format>, dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m final_tfidf_matrix \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# Calculate the number of batches needed\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m num_batches \u001b[39m=\u001b[39m tfidf_matrix_description\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m] \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m batch_size \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[39m# Process data in batches\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(num_batches)):\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define batch size (the number of columns to process in each batch)\n",
    "batch_size = 1000\n",
    "\n",
    "# Initialize an empty final matrix\n",
    "final_tfidf_matrix = None\n",
    "\n",
    "# Calculate the number of batches needed\n",
    "num_batches = tfidf_matrix_description.shape[1] // batch_size + 1\n",
    "\n",
    "# Process data in batches\n",
    "for i in tqdm(range(num_batches)):\n",
    "    start_col = i * batch_size\n",
    "    end_col = (i + 1) * batch_size\n",
    "\n",
    "    # Slice and horizontally concatenate the TF-IDF matrices in this batch\n",
    "    batch_matrix = np.hstack((tfidf_matrix_description[:, start_col:end_col].toarray(),\n",
    "                               tfidf_matrix_niche_shelves[:, start_col:end_col].toarray(),\n",
    "                               tfidf_matrix_common[:, start_col:end_col].toarray()))\n",
    "\n",
    "    if final_tfidf_matrix is None:\n",
    "        final_tfidf_matrix = batch_matrix\n",
    "    else:\n",
    "        final_tfidf_matrix = np.hstack((final_tfidf_matrix, batch_matrix))\n",
    "\n",
    "    # Free up memory by deleting the batch_matrix\n",
    "    del batch_matrix\n",
    "\n",
    "# Now, final_tfidf_matrix contains the concatenated TF-IDF matrices in batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('final_tfidf_matrix.npy', final_tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "c08c6aee2ba52dd3c42edb091342951b7c5600de1e66c997b8c9de0ad8e1d3be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
